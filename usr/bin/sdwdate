#!/usr/bin/python3 -u

import sys
import logging
import signal
import os
import glob
import time
from datetime import datetime
import random
from random import randint
from subprocess import Popen, call, PIPE, check_output
import pickle
import re
from shutil import rmtree

from sdwdate.remote_times import get_time_from_servers
from sdwdate.config import read_pools
from sdwdate.timesanitycheck import timesanitycheck
from sdwdate.proxy_settings import proxy_settings

from guimessages.translations import _translations

import sdnotify

n = sdnotify.SystemdNotifier()
n.notify("READY=1")
n.notify("STATUS=Starting...")


class Pool:
    def __init__(self, pool):
        self.url, self.comment = read_pools(pool, 'production')
        self.url_random = []
        self.already_picked_index = []
        self.invalid_urls = 0
        self.done = False

    @property
    def url_range(self):
        return len(self.url)

    @property
    def allowed_failures(self):
        if os.path.exists('/etc/sdwdate.d/'):
            files = sorted(glob.glob('/etc/sdwdate.d/*.conf'))
            for f in files:
                with open(f) as conf:
                    lines = conf.readlines()
                for line in lines:
                    if line.startswith('MAX_FAILURE_RATIO'):
                        failure_ratio = re.search(r'=(.*)', line).group(1)
            return int(len(self.url) * float(failure_ratio))
        else:
            return int(len(self.url) * 0.34)
        return int(len(self.url) * 0.34)



class Sdwdate:
    def __init__(self):
        self.iteration = 0
        self.number_of_pools = 3

        self.pools = [Pool(pool) for pool in range(self.number_of_pools)]
        ## Could get it here to prevent reading the file in sdwdate_loop for each Unreachable url.
        #self.allowed_failures = [Pool(pool).allowed_failures for pool in range(self.number_of_pools)]
        self.urls = []
        self.url_random = []
        self.valid_urls = []
        self.unixtimes = []
        self.pools_diff = []
        self.invalid_urls = []
        self.url_errors = []

        self.median = 0
        self.range_nanoseconds = 999999999
        self.new_diff = 0
        self.newdiff_nanoseconds = 0

        self.sclockadj_pid = 0

        self.first_success_path = '/var/run/sdwdate/first_success'
        self.success_path = '/var/run/sdwdate/success'
        self.status_path = '/var/run/sdwdate/status'
        self.msg_path = '/var/run/sdwdate/msg'

        self.success_icon = '/usr/share/icons/sdwdate-gui/Ambox_currentevent.svg.png'
        self.busy_icon = '/usr/share/icons/sdwdate-gui/620px-Ambox_outdated.svg.png'
        self.error_icon = '/usr/share/icons/sdwdate-gui/212px-Timeblock.svg.png'

        self.first_success = os.path.exists(self.first_success_path)
        self.success = os.path.exists(self.success_path)

        self.status = {'icon': '', 'message': ''}

        translations_path = '/usr/share/translations/sdwdate.yaml'
        translation = _translations(translations_path, 'sdwdate')
        self._ = translation.gettext

        self.proxy_ip, self.proxy_port = proxy_settings()

    @staticmethod
    def general_proxy_error(pools):
        '''
        This error occurs (at least) when Tor is not running.
        '''
        returned_error = 'connect error: Connection closed unexpectedly'
        if (pools[0] == returned_error and
                    pools[1] == returned_error and
                    pools[2] == returned_error):
            return True
        return False

    @staticmethod
    def general_timeout_error(pools):
        '''
        This error occurs (at least) when internet connection is down.
        '''
        returned_error = 'Timeout'
        if (pools[0] == returned_error and
                    pools[1] == returned_error and
                    pools[2] == returned_error):
            return True
        return False

    @staticmethod
    def check_remote(remote, value, comment):
        '''
        Check returned value. True if numeric.
        '''
        try:
            n = int(value)
            message = "remote: " + remote + " status: True"
            logger.info(message)
            message = "remote: " + remote + " comment: " + comment
            logger.info(message)
            return True
        except ValueError:
            message = "remote: " + remote + " status: False: " + str(value)
            logger.info(message)
            message = "remote: " + remote + " comment: " + comment
            logger.info(message)
            if value == "sigterm":
               exit_handler()
            return False

    def get_comment(self, remote):
        ''' For logging the comments, get the index of the url
            to get it from pool.comment.
        '''
        url_comment = ''
        for url in self.pools:
            try:
                url_index = url.url.index(remote)
                url_comment = url.comment[url_index]
            except ValueError:
                pass
        return url_comment

    def time_sanity_check(self, unixtime):
        status, time_one, time_two = timesanitycheck(unixtime)

        if status == 'sane':
            message = (self._('tsc_1') + status + self._('tsc_2') + time_one)
            # 'The clock is %s. Current time "%s".' % (status, time_one)
        elif status == 'slow':
            message = (self._('tsc_1') + status + self._('tsc_2') + time_one
                            + self._('slow_clock') + time_two) + self._('cause')
        elif status == 'fast':
            message = (self._('tsc_1') + status + self._('tsc_2') + time_one
                            + self._('fast_clock') + time_two) + self._('cause')
        elif status == 'insane':
            message = "insane"

        return status, message

    def build_median(self):
        '''
        Get the median (not average) from the list of values.
        '''
        diffs = sorted(self.pools_diff)
        message = 'Pool differences, sorted: %s' % diffs
        logger.info(message)
        self.median = diffs[(len(diffs) // 2)]

    def set_new_time(self):
        '''
        Do not set time if diff = 0.
        '''
        if self.median == 0:
            message = 'Time difference = 0. Not setting time.'
            logger.info(message)
            return False
        else:
            return True

    def add_subtract_nanoseconds(self):
        '''
        Could we replace this in sdwdate_loop pool_diff calculations?
        -> int(web_time) - old_unixtime
        '''
        signs = ['+', '-']
        sign = randint(0, 1)
        nanoseconds = randint(0, self.range_nanoseconds)
        seconds = float(nanoseconds) / 1000000000

        if sign == 0:
            self.new_diff = self.median + seconds
        else:
            self.new_diff = self.median - seconds

        self.newdiff_nanoseconds = int(self.new_diff * 1000000000)

        # print 'nanoseconds %s' % nanoseconds
        message = 'Median time difference: %s' % self.median
        logger.info(message)
        message = 'Seconds to add: %s %s' % (signs[sign], seconds)
        logger.info(message)
        message = 'New time difference: %s' % self.new_diff
        logger.info(message)

    def run_sclockadj(self):
        '''
        Set time with sneaky_clock_adjuster.
        '''
        if self.newdiff_nanoseconds > 0:
            add_subtract = "--add"
        else:
            add_subtract = "--subtract"
        cmd = [
            "sudo",
            "--non-interactive",
            "INLINEDIR=/var/cache/sdwdate/sclockadj",
            "/usr/lib/sdwdate/sclockadj",
            "--no-debug",
            "--no-verbose",
            "--no-systohc",
            "--no-first-wait",
            "--move-min", "5000000",
            "--move-max", "5000000",
            "--wait-min", "1000000000",
            "--wait-max", "1000000000",
            add_subtract, str(abs(self.newdiff_nanoseconds))]

        ## Run sclockadj in a subshell.
        sclockadj = Popen(cmd)
        self.sclockadj_pid = sclockadj.pid

        message = 'Gradually adjusting the time by running sclockadj. PID: %s' % self.sclockadj_pid
        logger.info(message)

    def kill_sclockadj(self):
        cmd = 'sudo --non-interactive /usr/lib/sdwdate/sclockadj_kill_helper ' + str(self.sclockadj_pid)
        call(cmd, shell=True)
        self.sclockadj_pid = 0

    def set_time_using_date(self):
        old_unixtime = float('%.9f' % (time.time()))
        message = 'Old unixttime: %s' % (str(old_unixtime))
        logger.info(message)

        new_unixtime = float('%.9f' % (old_unixtime + self.new_diff))
        message = 'New unixtime : %s' % (str(new_unixtime))
        logger.info(message)

        ## Set new time.
        cmd = 'sudo --non-interactive /bin/date --set @' + str(new_unixtime)
        call(cmd, shell=True)

        message = 'Instantly setting the time by using command "%s"' % cmd
        logger.info(message)

    def strip_html(self, message):
        ## New line for log.
        tmp_message = re.sub('<br>', '\n', message)
        ## Strip remaining HTML.
        return re.sub('<[^<]+?>', '', tmp_message)

    def write_status(self, *args):
        self.status['icon'] = args[0]
        self.status['message'] = args[1]
        msg = bytes(args[1], encoding = 'utf-8')
        with open(self.status_path, 'wb') as f:
            pickle.dump(self.status, f)
            f.close()

        with open(self.msg_path, 'wb') as msgf:
            msgf.write(msg)
            msgf.close()

    def sdwdate_loop(self):
        '''
        Check remotes.
        Pick a random url in each pool, check the returned value.
        Append valid urls if time is returned, otherwise restart a cycle
        with a new random url, until every pool has a time value.
        '''
        message = "Start fetching remote times."
        logger.info(message)

        current_unixtime = time.time()
        time_sanity_check_status, message = self.time_sanity_check(current_unixtime)
        stripped_message = self.strip_html(message)

        if time_sanity_check_status == 'sane':
            logger.info(stripped_message)
        else:
            return self.error_icon, 'error', message

        fetching_msg = self._('fetching')
        restricted_msg = self._('restricted')
        if self.success:
            self.write_status(self.success_icon, fetching_msg)
            logger.info(fetching_msg)
        else:
            if not self.first_success:
                self.write_status(self.busy_icon, (fetching_msg + restricted_msg))
                logger.info(fetching_msg + restricted_msg)
            else:
                self.write_status(self.success_icon, fetching_msg)
                logger.info(fetching_msg)

        while len(self.valid_urls) < self.number_of_pools:
            self.iteration += 1
            message = 'Running sdwdate fetch loop. iteration: %s' % self.iteration
            logger.info(message)

            ## Clear the lists.
            self.urls[:] = []
            self.url_random[:] = []

            for pool in self.pools:
                if not pool.done:
                    pool_range = pool.url_range
                    url_index = random.randrange(0, pool_range)
                    while url_index in pool.already_picked_index:
                        url_index = random.randrange(0, pool_range)

                    pool.already_picked_index.append(url_index)
                    if len(pool.already_picked_index) >= pool_range:
                        pool_number = self.pools.index(pool) + 1
                        message = self._('no_valid_time') + str(pool_number) + self._('restart')
                        logger.warning(message)
                        return self.error_icon, 'error', message

                    pool.url_random.append(pool.url[url_index])
                    self.url_random.append(pool.url[url_index])

            if len(self.url_random) > 0:
                message = 'Requested urls %s' % self.url_random
                logger.info(message)

                self.urls, self.returned_values = get_time_from_servers(self.url_random,
                                                                        self.proxy_ip,
                                                                        self.proxy_port)

                if len(self.urls) == 0:
                    message = self._('no_value_returned') + self._('restart')
                    return self.error_icon, 'error', message

                message = 'Returned urls "%s"' % self.urls
                logger.info(message)

            else:
                message = self._('list_not_built') + self._('restart')
                return self.error_icon, 'error', message

            for i in range(len(self.urls)):
                if self.check_remote(self.urls[i], self.returned_values[i], self.get_comment(self.urls[i])):
                    self.valid_urls.append(self.urls[i])
                    self.unixtimes.append(self.returned_values[i])
                else:
                    self.invalid_urls.append(self.urls[i])
                    self.url_errors.append(self.returned_values[i])

            if self.iteration >= 3:
               if len(self.returned_values) >= 3:
                     if self.general_proxy_error(self.returned_values):
                        message = self._('general_proxy_error')
                        return self.error_icon, 'error', message
                     if self.general_timeout_error(self.returned_values):
                        message = self._('general_timeout_error')
                        return self.error_icon, 'error', message

            for i in range(len(self.urls)):
               for pool in self.pools:
                  if self.urls[i] in pool.url_random:
                     pool.invalid_urls += 1
                     if pool.invalid_urls >= pool.allowed_failures:
                        message = (self._('max_pool_failures_1') +
                                       str(self.pools.index(pool) + 1) +
                                       ' (' + str(pool.invalid_urls) + ' of ' +
                                       str(len(pool.url)) + ')' +
                                       self._('max_pool_failures_2') + '<br>')
                        return self.error_icon, 'error', message

            old_unixtime = (time.time())

            for pool in self.pools:
                if not pool.done:
                    for url in pool.url_random:
                        pool.done = url in self.valid_urls
                        if pool.done:
                            ## Values are returned randomly. Get the index of the url.
                            index = self.valid_urls.index(url)
                            ## Pool matching web time.
                            web_unixtime = int(self.unixtimes[index])
                            sanitycheck_status, sanitycheck_message = self.time_sanity_check(web_unixtime)
                            if sanitycheck_status == 'sane':
                                web_time = (datetime.strftime(datetime.fromtimestamp(web_unixtime),
                                                              '%a %b %d %H:%M:%S UTC %Y'))
                                pool_diff = int(web_unixtime) - int(old_unixtime)
                                self.pools_diff.append(pool_diff)
                                pool_number = self.pools.index(pool) + 1
                                message = ('Pool %s last url: %s, web unixtime: %s, web time: %s, diff: %s seconds'
                                           % (pool_number, url, web_unixtime, web_time, pool_diff))
                                logger.info(message)
                            else:
                                pool.done = False
                                del self.valid_urls[index]
                                self.invalid_urls.append(url)
                                message = ('%s: time sanity check failed, server time is %s'
                                           % (url, sanitycheck_status))
                                logger.warning(message)

        message = "End fetching remote times."
        logger.info(message)

        message = self._('success')
        return self.success_icon, 'success', message


def exit_handler():
    n.notify("STATUS=Shutting down...")
    n.notify("WATCHDOG=1")
    n.notify("STOPPING=1")

    icon = sdwdate.error_icon
    message = sdwdate._('user_kill')
    stripped_message = sdwdate.strip_html(message)
    sdwdate.write_status(icon, message)

    if sdwdate.sclockadj_pid != 0:
        sdwdate.kill_sclockadj()

    logger.info("delete temp_dir: {}".format(temp_dir_str))
    ## rmtree can fail if exit_handler is invoked multiple times.
    try:
       rmtree(temp_dir_bytes)
    except:
       logger.info("deleting temp_dir failed: {}".format(temp_dir_str))

    logger.info(stripped_message)
    sys.exit(143)


def signal_sigterm_handler(signum, frame):
    exit_handler()


def prerequisite_check():
    message = ''
    previous_messsage = ''
    sdwdate = Sdwdate()
    loop_counter = 0
    loop_max = 10000
    prerequisite_check_sleep_seconds = 0
    while True:
        n.notify("WATCHDOG=1")
        if loop_counter >= loop_max:
            loop_counter = 0
        loop_counter += 1
        msg = "STATUS=Running sdwdate prerequisite_check loop. prerequisite_check_sleep_seconds: " + \
str(prerequisite_check_sleep_seconds) + " iteration: " + str(loop_counter) + " / " + str(loop_max)
        n.notify(msg)

        ## Wait one second after first failure. Two at second failure etc.
        ## Up to a maximum of ten seconds wait between attempts.
        ## The rationale behind this is to be quick at boot time while not
        ## stressing the system.
        prerequisite_check_sleep_seconds += 1
        if prerequisite_check_sleep_seconds >= 10:
            prerequisite_check_sleep_seconds = 10
        prerequisite_status = Popen(prerequisite_path,
                                    stdout=PIPE,
                                    stderr=PIPE)
        value, error = prerequisite_status.communicate()
        value = value.decode('UTF-8')
        if value == '':
            message = 'Prerequisite check: ok.'
            logger.info(message)
            return True
        else:
            message = 'Prerequisite check:<br> %s' % value.strip()
            if message != previous_messsage:
                previous_messsage = message
                stripped_message = sdwdate.strip_html(message)
                logger.warning(stripped_message)
                icon = sdwdate.busy_icon
                sdwdate.write_status(icon, message)
                prerequisite_check_sleep_seconds = 0
            time.sleep(prerequisite_check_sleep_seconds)


if __name__ == "__main__":
    logger = logging.getLogger('sdwdate')
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s", datefmt='%Y-%m-%d %H:%M:%S')
    file_handler = logging.FileHandler('/var/log/sdwdate.log')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    self_pid = os.getpid()
    pid_message = 'sdwdate started. PID: %s' % self_pid
    logger.info(pid_message)

    ## Create TEMP_DIR for te_pe_tb_check.
    temp_dir_bytes = check_output(["mktemp", "--directory"]).strip()
    temp_dir_str = temp_dir_bytes.decode("utf-8")
    logger.info("create temp_dir: {}".format(temp_dir_str))
    os.environ["TEMP_DIR"] = temp_dir_str

    run_prerequisite = False
    prerequisite_path = '/usr/lib/anon-shared-helper-scripts/te_pe_tb_check'
    if os.access(prerequisite_path, os.X_OK):
        run_prerequisite = True

    signal.signal(signal.SIGTERM, signal_sigterm_handler)

    sdwdate = Sdwdate()
    proxy_message = ('Tor socks host: %s  Tor socks port: %s'
                     % (sdwdate.proxy_ip, sdwdate.proxy_port))
    logger.info(proxy_message)

    loop_counter = 0
    loop_max = 10000

    while True:
        if loop_counter >= loop_max:
            loop_counter = 0
        loop_counter += 1

        msg = "Running sdwdate main loop. iteration: " + str(loop_counter) + " / " + str(loop_max)
        logger.info(msg)

        if run_prerequisite:
            prerequisite_check()

        msg = "STATUS=Running sdwdate main loop. iteration: " + str(loop_counter) + " / " + str(loop_max)
        n.notify(msg)
        n.notify("WATCHDOG=1")

        sdwdate = Sdwdate()
        icon, status, sdwdate_message_from_loop = sdwdate.sdwdate_loop()
        n.notify("WATCHDOG=1")

        if status == 'success':
            sdwdate.build_median()
            sdwdate.add_subtract_nanoseconds()
            if sdwdate.set_new_time():
                if sdwdate.success:
                    sdwdate.run_sclockadj()
                else:
                    sdwdate.set_time_using_date()
            if not sdwdate.first_success:
                f = open(sdwdate.first_success_path, 'w')
                f.close()

            f = open(sdwdate.success_path, 'w')
            f.close()
            ## If we make the sleep period configurable one day, we need to
            ## advice the user to also adjust WatchdogSec= in sdwdate's systemd
            ## unit file.
            sleep_time = randint(60, 180)
            log_level = 'info'

        elif status == 'error':
            sleep_time = 10
            log_level = 'warning'

        message = (sdwdate_message_from_loop + " " + sdwdate._('sleeping') +
                   str(sleep_time) + sdwdate._('minutes'))
        stripped_message = sdwdate.strip_html(message)

        sdwdate.write_status(icon, message)

        if log_level == 'info':
            logger.info(stripped_message)
        elif log_level == 'warning':
            logger.warning(stripped_message)

        n.notify("WATCHDOG=1")

        seconds_to_sleep = sleep_time * 60
        ## Using sh sleep in place of python's time.sleep(seconds_to_sleep).
        ## The latter uses the system clock for its inactive state time.
        ## It becomes utterly confused when sclockadj is running.
        cmd = 'sleep %s' % seconds_to_sleep
        call(cmd, shell=True)

        if sdwdate.sclockadj_pid != 0:
            sdwdate.kill_sclockadj()
